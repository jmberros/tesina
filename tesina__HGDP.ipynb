{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HGDP Max Plank dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>rs6685064</th>\n",
       "      <th>rs12085319</th>\n",
       "      <th>rs4920310</th>\n",
       "      <th>rs6684063</th>\n",
       "      <th>rs7515867</th>\n",
       "      <th>rs11264115</th>\n",
       "      <th>rs11206160</th>\n",
       "      <th>rs2984915</th>\n",
       "      <th>rs12743599</th>\n",
       "      <th>rs12727814</th>\n",
       "      <th>...</th>\n",
       "      <th>rs2187239</th>\n",
       "      <th>rs762421</th>\n",
       "      <th>rs5748014</th>\n",
       "      <th>rs5754506</th>\n",
       "      <th>rs132663</th>\n",
       "      <th>rs5757362</th>\n",
       "      <th>rs9611566</th>\n",
       "      <th>rs16990991</th>\n",
       "      <th>rs1557553</th>\n",
       "      <th>rs801712</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>superpopulation</th>\n",
       "      <th>population</th>\n",
       "      <th>sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">EAS</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">Daur</th>\n",
       "      <th>HGDP01213</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGDP01214</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGDP01217</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGDP01221</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGDP01222</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 340 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      rs6685064  rs12085319  rs4920310  \\\n",
       "superpopulation population sample                                        \n",
       " EAS            Daur       HGDP01213        1.0         0.0        1.0   \n",
       "                           HGDP01214        1.0         1.0        1.0   \n",
       "                           HGDP01217        1.0         0.0        1.0   \n",
       "                           HGDP01221        1.0         0.0        2.0   \n",
       "                           HGDP01222        1.0         1.0        0.0   \n",
       "\n",
       "                                      rs6684063  rs7515867  rs11264115  \\\n",
       "superpopulation population sample                                        \n",
       " EAS            Daur       HGDP01213        1.0        0.0         2.0   \n",
       "                           HGDP01214        2.0        0.0         0.0   \n",
       "                           HGDP01217        2.0        0.0         2.0   \n",
       "                           HGDP01221        2.0        0.0         1.0   \n",
       "                           HGDP01222        1.0        1.0         1.0   \n",
       "\n",
       "                                      rs11206160  rs2984915  rs12743599  \\\n",
       "superpopulation population sample                                         \n",
       " EAS            Daur       HGDP01213         2.0        0.0         2.0   \n",
       "                           HGDP01214         2.0        0.0         1.0   \n",
       "                           HGDP01217         1.0        1.0         1.0   \n",
       "                           HGDP01221         1.0        0.0         1.0   \n",
       "                           HGDP01222         1.0        0.0         1.0   \n",
       "\n",
       "                                      rs12727814    ...     rs2187239  \\\n",
       "superpopulation population sample                   ...                 \n",
       " EAS            Daur       HGDP01213         0.0    ...           1.0   \n",
       "                           HGDP01214         1.0    ...           0.0   \n",
       "                           HGDP01217         1.0    ...           0.0   \n",
       "                           HGDP01221         0.0    ...           0.0   \n",
       "                           HGDP01222         1.0    ...           0.0   \n",
       "\n",
       "                                      rs762421  rs5748014  rs5754506  \\\n",
       "superpopulation population sample                                      \n",
       " EAS            Daur       HGDP01213       2.0        1.0        0.0   \n",
       "                           HGDP01214       2.0        1.0        0.0   \n",
       "                           HGDP01217       0.0        0.0        0.0   \n",
       "                           HGDP01221       2.0        0.0        1.0   \n",
       "                           HGDP01222       2.0        1.0        0.0   \n",
       "\n",
       "                                      rs132663  rs5757362  rs9611566  \\\n",
       "superpopulation population sample                                      \n",
       " EAS            Daur       HGDP01213       1.0        1.0        1.0   \n",
       "                           HGDP01214       0.0        2.0        2.0   \n",
       "                           HGDP01217       0.0        2.0        0.0   \n",
       "                           HGDP01221       0.0        0.0        1.0   \n",
       "                           HGDP01222       1.0        1.0        0.0   \n",
       "\n",
       "                                      rs16990991  rs1557553  rs801712  \n",
       "superpopulation population sample                                      \n",
       " EAS            Daur       HGDP01213         2.0        1.0       0.0  \n",
       "                           HGDP01214         0.0        NaN       2.0  \n",
       "                           HGDP01217         2.0        0.0       0.0  \n",
       "                           HGDP01221         2.0        2.0       1.0  \n",
       "                           HGDP01222         0.0        1.0       0.0  \n",
       "\n",
       "[5 rows x 340 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This cell takes the MaxPlank bed with all genotypes\n",
    "# and extracts a traw with a subset of genotypes for each panel\n",
    "\n",
    "from subprocess import call\n",
    "from os.path import join\n",
    "\n",
    "from sources.max_plank import MaxPlank\n",
    "from components.panel import Panel\n",
    "\n",
    "\n",
    "WORKDIR = MaxPlank.BASE_DIR\n",
    "\n",
    "for panel in Panel.all_panels_and_subpanels(): #+ Panel.all_control_panels():\n",
    "        \n",
    "    snps_filename = panel.write_snps_file(WORKDIR)\n",
    "    \n",
    "    command = [\"plink\",\n",
    "        \"--bfile\", MaxPlank.LABEL,\n",
    "        \"--extract\", snps_filename,\n",
    "        \"--recode\", \"A-transpose\",\n",
    "        \"--out\", join(WORKDIR, panel.label)\n",
    "    ]    \n",
    "    call(command)\n",
    "\n",
    "\n",
    "Panel(\"GAL_Completo\").genotypes(\"MaxPlank\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>rs6685064</th>\n",
       "      <th>rs12085319</th>\n",
       "      <th>rs4920310</th>\n",
       "      <th>rs6684063</th>\n",
       "      <th>rs7515867</th>\n",
       "      <th>rs11264115</th>\n",
       "      <th>rs11206160</th>\n",
       "      <th>rs2984915</th>\n",
       "      <th>rs12743599</th>\n",
       "      <th>rs12727814</th>\n",
       "      <th>...</th>\n",
       "      <th>rs2187239</th>\n",
       "      <th>rs762421</th>\n",
       "      <th>rs5748014</th>\n",
       "      <th>rs5754506</th>\n",
       "      <th>rs132663</th>\n",
       "      <th>rs5757362</th>\n",
       "      <th>rs9611566</th>\n",
       "      <th>rs16990991</th>\n",
       "      <th>rs1557553</th>\n",
       "      <th>rs801712</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>superpopulation</th>\n",
       "      <th>population</th>\n",
       "      <th>sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 340 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [rs6685064, rs12085319, rs4920310, rs6684063, rs7515867, rs11264115, rs11206160, rs2984915, rs12743599, rs12727814, rs12022561, rs6681719, rs12065716, rs12021830, rs6693833, rs12123239, rs927900, rs2025236, rs1041310, rs10779334, rs12142968, rs7525142, rs9725312, rs6677662, rs41009, rs181130, rs2140701, rs798364, rs6711746, rs10175357, rs305163, rs11124754, rs10179648, rs6740875, rs4671675, rs7584385, rs10496176, rs7601949, rs12328713, rs1257084, rs7598069, rs6431064, rs1036543, rs7589619, rs6429990, rs6759948, rs6759814, rs3927978, rs2695735, rs7568054, rs6707773, rs1606237, rs16851773, rs10186877, rs1472714, rs4109078, rs1605524, rs9863982, rs978979, rs862500, rs9833943, rs783511, rs3925004, rs13097560, rs7644167, rs2317212, rs7630522, rs4855697, rs7630111, rs2869782, rs2937673, rs16832787, rs12638324, rs2855557, rs1586861, rs868767, rs9832471, rs2106124, rs6806083, rs6770338, rs2378269, rs13327370, rs7665516, rs719776, rs6817183, rs11725412, rs10026397, rs11051, rs12650513, rs1486498, rs6855458, rs4693573, rs17014118, rs2089990, rs2851060, rs920559, rs6533426, rs4541508, rs6533531, rs7664927, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 340 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from components.dataset import Dataset\n",
    "from components.panel import Panel\n",
    "\n",
    "\n",
    "Panel(\"GAL_Completo\").genotypes(\"MaxPlank\", dataset=Dataset(\"LEA\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def write_definition(pop, country, region):\n",
    "    if country is np.nan and region is np.nan:\n",
    "        return \"{} people\".format(pop)\n",
    "    \n",
    "    if country is np.nan:\n",
    "        return \"{} from {}\".format(pop, region)\n",
    "    \n",
    "    if region is np.nan:\n",
    "        return \"{} from {}\".format(pop, country)\n",
    "        \n",
    "    return \"{} from {} ({})\".format(pop, country, region)\n",
    "    \n",
    "\n",
    "df[\"description\"] = [write_definition(*pcr) for pcr in zip(df.index, df[\"country\"], df[\"region\"])]\n",
    "df.to_csv(MaxPlank.POPULATIONS_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "merge() missing 1 required positional argument: 'right'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-6d7ec217c506>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmax_plank\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSource\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"MaxPlank\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mthousand_genomes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/juan/repos/tesina/components/source.py\u001b[0m in \u001b[0;36msamples\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0msamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"sample\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0msamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"population\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"superpopulation\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: merge() missing 1 required positional argument: 'right'"
     ]
    }
   ],
   "source": [
    "from components.source import Source\n",
    "\n",
    "\n",
    "thousand_genomes = Source(\"1000Genomes\")\n",
    "max_plank = Source(\"MaxPlank\")\n",
    "\n",
    "thousand_genomes.samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read HDGP markers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para descargar los datos de HGDP usÃ© ftp_download_HGDP.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a .traw file for each Panel\n",
    "\n",
    "* Para cada panel, crear un `.traw` extrayendo los SNPs del archivo `.bed` general de (cada dataset de) HGDP.\n",
    "* `HGDP` lee esos `.traw` por panel!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CEPH dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn = \"~/tesina/HGDP_data/dataset_1_HGDP-CEPH_v3/hgdp-ceph-marker.out\"\n",
    "hgdp_ceph_markers = pd.read_csv(fn, sep=\"\\t\")\n",
    "hgdp_ceph_markers = hgdp_ceph_markers.rename(columns={\"chrom\": \"chr\", \"physical_pos\": \"pos\"})\n",
    "mask = hgdp_ceph_markers[\"type_marker\"].isin([\"SNP\", \"snp\"])\n",
    "hgdp_ceph_markers = hgdp_ceph_markers[mask].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn = \"~/tesina/HGDP_data/dataset_1_HGDP-CEPH_v3/hgdp-ceph-geno.out\"\n",
    "# Filter only biallelic SNPs!\n",
    "hgdp_ceph_genotypes = pd.read_csv(fn, sep=\"\\t\", index_col=\"hgdp_id\")\n",
    "hgdp_ceph_genotypes.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filtrar esos 5,4 M de genotipos por el mkr_ceph_id de los rs de galanter\n",
    "# ojo con la RAM!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stanford dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn = \"~/tesina/HGDP_data/dataset_2_supp1_Stanford/hgdp/HGDP_Map.txt\"\n",
    "hgdp_stanford_markers = pd.read_csv(fn, sep=\"\\t\", names=[\"dbsnp_id\", \"chr\", \"pos\"],\n",
    "                                    index_col=\"dbsnp_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uni of Michigan dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from os.path import isfile\n",
    "\n",
    "dumpfile = \"./dumpfiles/HGDP_michigan_markers.csv\"\n",
    "\n",
    "if isfile(dumpfile):\n",
    "    dtypes = {\"dbsnp_id\": str, \"chr\": str, \"pos_build_36\": int, \"pos_build_35\": int}\n",
    "    hgdp_michigan_markers = pd.read_csv(dumpfile, index_col=\"dbsnp_id\", dtype=dtypes)\n",
    "else:    \n",
    "    markers_per_chr = []\n",
    "    \n",
    "    # The *.map files were generated with \"parse_HGDP_UMichigan_data.sh\"\n",
    "    for fn in glob(\"~/tesina/HGDP_data/dataset_3_supp2_UMichigan/GENO/chr*.map\"):\n",
    "        markers_per_chr.append(pd.read_csv(fn, sep=\"\\s+\").transpose())\n",
    "\n",
    "    hgdp_michigan_markers = pd.concat(markers_per_chr).drop(0, axis=1)\n",
    "    hgdp_michigan_markers.columns = [\"chr\", \"pos_build_36\", \"pos_build_35\"]\n",
    "    hgdp_michigan_markers[\"pos\"] = hgdp_michigan_markers[\"pos_build_36\"]\n",
    "    hgdp_michigan_markers.index.name = \"dbsnp_id\"\n",
    "    hgdp_michigan_markers.to_csv(dumpfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Plank Institute datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn = \"~/tesina/HGDP_data/dataset_4_supp3_MPlank/hgdpceph.affy500k.map.gz\"\n",
    "hgdp_maxplank_markers = pd.read_csv(fn, sep=\"\\t\", names=[\"chr\", \"dbsnp_id\", \"?\", \"pos\"],\n",
    "                                    usecols=[\"chr\", \"dbsnp_id\", \"pos\"], index_col=\"dbsnp_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Harvard dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn = \"~/tesina/HGDP_data/dataset_11_supp10_Harvard/Harvard_HGDP-CEPH/all_snp.map.gz\"\n",
    "hgdp_harvard_markers = pd.read_csv(fn, sep=\"\\t\", names=[\"chr\", \"Affy SNP ID\", \"?\", \"pos\"],\n",
    "                                   usecols=[\"chr\", \"Affy SNP ID\", \"pos\"])\n",
    "\n",
    "fn = \"~/tesina/HGDP_data/dataset_11_supp10_Harvard/Axiom_GW_HuOrigin.na35.annot.csv.tar.gz\"\n",
    "affy_human_origins = pd.read_csv(fn, comment=\"#\", skiprows=1, index_col=\"Affy SNP ID\",\n",
    "                                 usecols=[\"Affy SNP ID\", \"dbSNP RS ID\"])\n",
    "\n",
    "hgdp_harvard_markers = hgdp_harvard_markers.set_index(\"Affy SNP ID\")\n",
    "hgdp_harvard_markers = hgdp_harvard_markers.join(affy_human_origins)\n",
    "hgdp_harvard_markers = hgdp_harvard_markers.rename(columns={\"dbSNP RS ID\": \"dbsnp_id\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UCLA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn = \"~/tesina/HGDP_data/dataset_15_supp15_UCLA/snp_info.csv\"\n",
    "hgdp_ucla_markers = pd.read_csv(fn, names=[\"_\", \"_\", \"chr\", \"pos\", \"dbsnp_id\"],\n",
    "                                usecols=[\"chr\", \"pos\", \"dbsnp_id\"], skiprows=1).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intersection GAL x HGDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hgdp_panels = {\n",
    "    \"CEPH\": hgdp_ceph_markers,\n",
    "    \"Stanford\": hgdp_stanford_markers,\n",
    "    \"MaxPlank\": hgdp_maxplank_markers,\n",
    "    \"Harvard\": hgdp_harvard_markers,\n",
    "    \"UCLA\": hgdp_ucla_markers,\n",
    "    \"UMichigan\": hgdp_michigan_markers,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "galanter_HGDP_matches = pd.DataFrame({\"dbsnp_id\": galanter.index})\n",
    "galanter_HGDP_matches = galanter_HGDP_matches.set_index(\"dbsnp_id\")\n",
    "\n",
    "for panel_name, markers in hgdp_panels.items():\n",
    "    print(panel_name, len(markers))\n",
    "    galanter_HGDP_matches[panel_name] = \\\n",
    "        galanter_HGDP_matches.index.map(lambda x: x in markers.index.values)\n",
    "\n",
    "galanter_HGDP_matches[\"hits\"] = galanter_HGDP_matches.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "galanter_hgdp_indices = {}\n",
    "\n",
    "print(\"Galanter Matches in HGDP panels:\")\n",
    "for hgdp_panel_name, markers in hgdp_panels.items():\n",
    "    matches = galanter_HGDP_matches[hgdp_panel_name]\n",
    "    intersection_count = len(matches[matches])\n",
    "    \n",
    "    if intersection_count > 0:\n",
    "        galanter_hgdp_indices[hgdp_panel_name] = {}\n",
    "        galanter_hgdp_indices[hgdp_panel_name][\"galT\"] = galanter_HGDP_matches[matches].index\n",
    "        galanter_hgdp_indices[hgdp_panel_name][\"galP\"] = \\\n",
    "            galanter_HGDP_matches[matches].loc[present.index].dropna(axis=0).index\n",
    "        \n",
    "        print(\"-\")\n",
    "        print(hgdp_panel_name, \"galT ->\",\n",
    "              len(galanter_hgdp_indices[hgdp_panel_name][\"galT\"]))\n",
    "        print(hgdp_panel_name, \"galP ->\",\n",
    "              len(galanter_hgdp_indices[hgdp_panel_name][\"galP\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HGDP populations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CEPH populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn = \"~/tesina/HGDP_data/dataset_1_HGDP-CEPH_v3/hgdp-ceph-pop.out\"\n",
    "usecols = [\"population_name\", \"population_id\", \"nickname\"]\n",
    "hgdp_populations_detail = pd.read_csv(fn, sep=\"\\t\", usecols=usecols)\n",
    "hgdp_populations_detail.set_index(\"population_name\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "popcodes = dict(zip(hgdp_populations_detail.index.values,\n",
    "                    hgdp_populations_detail[\"nickname\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn = \"~/tesina/HGDP_data/dataset_1_HGDP-CEPH_v3/hgdp-ceph-unrelated.out\"\n",
    "hgdp_samples = pd.read_csv(fn, sep=\"\\t\", index_col=\"hgdp_id\")\n",
    "hgdp_samples[\"continent\"] = hgdp_samples[\"Region\"].map(hgdp_continents)\n",
    "hgdp_samples[\"population_name\"] = hgdp_samples[\"population\"]\n",
    "hgdp_samples[\"population\"] = hgdp_samples[\"population_name\"].map(popcodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regions = dict(zip(hgdp_samples[\"population_name\"],\n",
    "                   hgdp_samples[\"Region\"]))\n",
    "continents = dict(zip(hgdp_samples[\"population_name\"],\n",
    "                      hgdp_samples[\"continent\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hgdp_populations_detail[\"continent\"] = \\\n",
    "    hgdp_populations_detail.index.map(lambda x: continents[x])\n",
    "hgdp_populations_detail[\"region\"] = \\\n",
    "    hgdp_populations_detail.index.map(lambda x: regions[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HGDP genotypes and populations read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hgdp_genotypes = defaultdict(OrderedDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MaxPlank dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn = \"~/tesina/HGDP_data/dataset_4_supp3_MPlank/hgdpceph.affy500k.AT.traw.parsed\"\n",
    "df = pd.read_csv(fn, sep=\"\\s+\")\n",
    "renamed_columns = [s.split(\"_\")[-1] for s in df.columns]\n",
    "df.columns = renamed_columns\n",
    "df.rename(columns={\"SNP\": \"dbsnp_id\"}, inplace=True)\n",
    "df.set_index(\"dbsnp_id\", inplace=True)\n",
    "\n",
    "for panel_name in panels:\n",
    "    indices = galanter_hgdp_indices[\"MaxPlank\"][panel_name]\n",
    "    hgdp_genotypes[\"MaxPlank\"][panel_name] = df.loc[indices]\n",
    "\n",
    "df = None # Hope this cleans the big dataframe from memory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "latinos = ['Colombians', 'Karitiana', 'Maya', 'Surui', 'Pima']\n",
    "europeans = ['Basque', 'Bergamo', 'French']\n",
    "africans = ['BiakaPygmy' 'Bantu', 'Mandenka']\n",
    "middle_eastern = ['Balochi', 'Bedouin', 'Brahui', 'Mongola']\n",
    "oceania = ['Papuan']\n",
    "east_asian = ['Dai']\n",
    "\n",
    "LEA_populations = latinos + africans + europeans\n",
    "world_populations = LEA_populations + middle_eastern + oceania\n",
    "\n",
    "datasets_mplank = OrderedDict()\n",
    "dataset_definitions = {\n",
    "    \"MaxPlank LEA\": LEA_populations,\n",
    "    \"MaxPlank World\": world_populations,\n",
    "}\n",
    "\n",
    "for dataset_label, population_list in dataset_definitions.items():\n",
    "    mask = mplank_populations[\"population\"].isin(population_list)\n",
    "    sample_indices = mplank_populations[mask].index\n",
    "    dataset = hgdp_genotypes[\"MaxPlank\"][\"galT\"].loc[:, sample_indices].transpose()\n",
    "    datasets_mplank[dataset_label] = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% run plot_PCAs.py\n",
    "\n",
    "hgdp_panel_name = \"MaxPlank\"\n",
    "\n",
    "panel_indices = OrderedDict()\n",
    "panel_indices['GAL Total'] = galanter.index\n",
    "panel_indices['GAL Parcial'] = present.index\n",
    "\n",
    "for dataset_label, dataset in datasets_mplank.items():\n",
    "    pca = plot_PCAs(dataset_label, panel_indices, dataset,\n",
    "                    mplank_populations, plot_markers, plot_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
